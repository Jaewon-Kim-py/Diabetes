{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = join('C:', 'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data['Outcome']\n",
    "data = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, valid(80%)  와 test(20%) 분리  (stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_data, x_test, y_data, y_test = train_test_split(data,label, test_size=0.2,random_state=2021,shuffle=True,stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치를 평균으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(x_data[features],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in features:\n",
    "    x_data.loc[pd.isna(x_data[c]),c] = x_mean[c]\n",
    "    x_test.loc[pd.isna(x_test[c]),c] = x_mean[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pregnancies                 0\n",
       " Glucose                     0\n",
       " BloodPressure               0\n",
       " SkinThickness               0\n",
       " Insulin                     0\n",
       " BMI                         0\n",
       " DiabetesPedigreeFunction    0\n",
       " Age                         0\n",
       " dtype: int64,\n",
       " Pregnancies                 0\n",
       " Glucose                     0\n",
       " BloodPressure               0\n",
       " SkinThickness               0\n",
       " Insulin                     0\n",
       " BMI                         0\n",
       " DiabetesPedigreeFunction    0\n",
       " Age                         0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(x_data).sum(), pd.isna(x_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.321</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.184332</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>0.652</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.946918</td>\n",
       "      <td>29.184332</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>0.209</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>71.946918</td>\n",
       "      <td>29.184332</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>32.731126</td>\n",
       "      <td>0.174</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>4.469349</td>\n",
       "      <td>121.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>0.203</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>4.469349</td>\n",
       "      <td>93.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.184332</td>\n",
       "      <td>156.865385</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>0.591</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.527</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "0       1.000000    128.0      98.000000      41.000000   58.000000   \n",
       "1       9.000000    130.0      70.000000      29.184332  156.865385   \n",
       "2       9.000000     57.0      80.000000      37.000000  156.865385   \n",
       "3       9.000000    170.0      74.000000      31.000000  156.865385   \n",
       "4       7.000000    119.0      71.946918      29.184332  156.865385   \n",
       "..           ...      ...            ...            ...         ...   \n",
       "609     3.000000     80.0      71.946918      29.184332  156.865385   \n",
       "610     4.469349    121.0      66.000000      30.000000  165.000000   \n",
       "611     4.469349     93.0      60.000000      29.184332  156.865385   \n",
       "612     3.000000     84.0      68.000000      30.000000  106.000000   \n",
       "613     1.000000     80.0      74.000000      11.000000   60.000000   \n",
       "\n",
       "           BMI  DiabetesPedigreeFunction   Age  \n",
       "0    32.000000                     1.321  33.0  \n",
       "1    34.200000                     0.652  45.0  \n",
       "2    32.800000                     0.096  41.0  \n",
       "3    44.000000                     0.403  43.0  \n",
       "4    25.200000                     0.209  37.0  \n",
       "..         ...                       ...   ...  \n",
       "609  32.731126                     0.174  22.0  \n",
       "610  34.300000                     0.203  33.0  \n",
       "611  35.300000                     0.263  25.0  \n",
       "612  31.900000                     0.591  25.0  \n",
       "613  30.000000                     0.527  22.0  \n",
       "\n",
       "[614 rows x 8 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = y_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "609    0\n",
       "610    1\n",
       "611    0\n",
       "612    0\n",
       "613    0\n",
       "Name: Outcome, Length: 614, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data, \n",
    "                                                      test_size=0.3,\n",
    "                                                      random_state=2021,\n",
    "                                                      shuffle=True,\n",
    "                                                      stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mean = np.mean(x_train[features], axis=0)\n",
    "x_train_std  = np.std(x_train[features], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[:, features] = (x_train[features] - x_train_mean) / x_train_std \n",
    "x_valid.loc[:, features] = (x_valid[features] - x_train_mean) / x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgb = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 1\ttraining's binary_logloss: 0.0666379\tvalid_1's auc: 0.807593\tvalid_1's binary_logloss: 0.628018\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[78]\ttraining's auc: 1\ttraining's binary_logloss: 0.098913\tvalid_1's auc: 0.807335\tvalid_1's binary_logloss: 0.588787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_valid, y_valid)], eval_metric= 'auc', verbose= 100, \n",
    "                early_stopping_rounds= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([131, 231, 132,  92,  71, 233, 237, 190])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance\n",
       "0  DiabetesPedigreeFunction         237\n",
       "1                       BMI         233\n",
       "2                   Glucose         231\n",
       "3                       Age         190\n",
       "4             BloodPressure         132\n",
       "5               Pregnancies         131\n",
       "6             SkinThickness          92\n",
       "7                   Insulin          71"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature': x_train.columns, 'importance': lgb.feature_importances_})\n",
    "importances = importances.sort_values(by='importance',ascending=False)\n",
    "importances.reset_index(drop=True, inplace=True)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 별로 search할 범위를 설정. \n",
    "bayesian_params = {\n",
    "    'max_depth': (6, 16), \n",
    "    'num_leaves': (24, 64), \n",
    "    'min_child_samples': (10, 200), \n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_bin':(10, 500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree,max_bin):\n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.01,\n",
    "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': int(round(num_leaves)), \n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample': max(min(subsample, 1), 0), \n",
    "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "        'max_bin':  max(int(round(max_bin)),10)\n",
    "    }\n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_valid, y_valid)], eval_metric= 'auc', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_proba = lgb_model.predict_proba(x_valid)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_valid, valid_proba)\n",
    "    \n",
    "    return roc_auc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 369.4   \u001b[0m | \u001b[0m 7.389   \u001b[0m | \u001b[0m 69.41   \u001b[0m | \u001b[0m 49.86   \u001b[0m | \u001b[0m 29.13   \u001b[0m | \u001b[0m 0.5895  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.906511\ttraining's binary_logloss: 0.452522\tvalid_1's auc: 0.80288\tvalid_1's binary_logloss: 0.521774\n",
      "[200]\ttraining's auc: 0.935305\ttraining's binary_logloss: 0.366618\tvalid_1's auc: 0.819861\tvalid_1's binary_logloss: 0.489633\n",
      "[300]\ttraining's auc: 0.951302\ttraining's binary_logloss: 0.317715\tvalid_1's auc: 0.820764\tvalid_1's binary_logloss: 0.491337\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's auc: 0.942796\ttraining's binary_logloss: 0.343618\tvalid_1's auc: 0.820377\tvalid_1's binary_logloss: 0.487502\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8204  \u001b[0m | \u001b[95m 0.8765  \u001b[0m | \u001b[95m 334.5   \u001b[0m | \u001b[95m 13.84   \u001b[0m | \u001b[95m 28.41   \u001b[0m | \u001b[95m 3.87    \u001b[0m | \u001b[95m 62.5    \u001b[0m | \u001b[95m 0.8083  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.817646\ttraining's binary_logloss: 0.554892\tvalid_1's auc: 0.764721\tvalid_1's binary_logloss: 0.578028\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.815998\ttraining's binary_logloss: 0.582501\tvalid_1's auc: 0.764721\tvalid_1's binary_logloss: 0.596933\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 0.5433  \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 12.17   \u001b[0m | \u001b[0m 193.1   \u001b[0m | \u001b[0m 29.14   \u001b[0m | \u001b[0m 38.85   \u001b[0m | \u001b[0m 0.7261  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.845221\ttraining's binary_logloss: 0.532139\tvalid_1's auc: 0.770984\tvalid_1's binary_logloss: 0.563877\n",
      "[200]\ttraining's auc: 0.846559\ttraining's binary_logloss: 0.488558\tvalid_1's auc: 0.783897\tvalid_1's binary_logloss: 0.533763\n",
      "[300]\ttraining's auc: 0.85172\ttraining's binary_logloss: 0.469745\tvalid_1's auc: 0.787384\tvalid_1's binary_logloss: 0.523407\n",
      "[400]\ttraining's auc: 0.854564\ttraining's binary_logloss: 0.460992\tvalid_1's auc: 0.790483\tvalid_1's binary_logloss: 0.518823\n",
      "[500]\ttraining's auc: 0.856523\ttraining's binary_logloss: 0.455914\tvalid_1's auc: 0.792807\tvalid_1's binary_logloss: 0.51662\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\ttraining's auc: 0.856595\ttraining's binary_logloss: 0.455985\tvalid_1's auc: 0.792549\tvalid_1's binary_logloss: 0.516643\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7925  \u001b[0m | \u001b[0m 0.6009  \u001b[0m | \u001b[0m 289.0   \u001b[0m | \u001b[0m 7.951   \u001b[0m | \u001b[0m 120.9   \u001b[0m | \u001b[0m 24.34   \u001b[0m | \u001b[0m 44.71   \u001b[0m | \u001b[0m 0.9115  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.78951\ttraining's binary_logloss: 0.552322\tvalid_1's auc: 0.726046\tvalid_1's binary_logloss: 0.587037\n",
      "[200]\ttraining's auc: 0.81368\ttraining's binary_logloss: 0.526566\tvalid_1's auc: 0.760847\tvalid_1's binary_logloss: 0.564208\n",
      "[300]\ttraining's auc: 0.81282\ttraining's binary_logloss: 0.520299\tvalid_1's auc: 0.761816\tvalid_1's binary_logloss: 0.553564\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's auc: 0.81313\ttraining's binary_logloss: 0.522031\tvalid_1's auc: 0.76272\tvalid_1's binary_logloss: 0.557102\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.8661  \u001b[0m | \u001b[0m 43.84   \u001b[0m | \u001b[0m 12.72   \u001b[0m | \u001b[0m 132.3   \u001b[0m | \u001b[0m 41.57   \u001b[0m | \u001b[0m 32.18   \u001b[0m | \u001b[0m 0.8087  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.84908\ttraining's binary_logloss: 0.5284\tvalid_1's auc: 0.776795\tvalid_1's binary_logloss: 0.559716\n",
      "[200]\ttraining's auc: 0.850932\ttraining's binary_logloss: 0.484108\tvalid_1's auc: 0.786222\tvalid_1's binary_logloss: 0.531205\n",
      "[300]\ttraining's auc: 0.854958\ttraining's binary_logloss: 0.465989\tvalid_1's auc: 0.788352\tvalid_1's binary_logloss: 0.520675\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's auc: 0.854026\ttraining's binary_logloss: 0.470107\tvalid_1's auc: 0.789644\tvalid_1's binary_logloss: 0.522634\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7896  \u001b[0m | \u001b[0m 0.6745  \u001b[0m | \u001b[0m 291.1   \u001b[0m | \u001b[0m 8.589   \u001b[0m | \u001b[0m 115.7   \u001b[0m | \u001b[0m 23.95   \u001b[0m | \u001b[0m 45.87   \u001b[0m | \u001b[0m 0.9968  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.980693\ttraining's binary_logloss: 0.373336\tvalid_1's auc: 0.809143\tvalid_1's binary_logloss: 0.519701\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.967861\ttraining's binary_logloss: 0.500084\tvalid_1's auc: 0.81108\tvalid_1's binary_logloss: 0.566243\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8111  \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 283.4   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.9665  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.853799\ttraining's binary_logloss: 0.507461\tvalid_1's auc: 0.789579\tvalid_1's binary_logloss: 0.545072\n",
      "[200]\ttraining's auc: 0.871063\ttraining's binary_logloss: 0.456728\tvalid_1's auc: 0.814437\tvalid_1's binary_logloss: 0.50621\n",
      "[300]\ttraining's auc: 0.881314\ttraining's binary_logloss: 0.429868\tvalid_1's auc: 0.817536\tvalid_1's binary_logloss: 0.494414\n",
      "[400]\ttraining's auc: 0.886882\ttraining's binary_logloss: 0.414568\tvalid_1's auc: 0.81702\tvalid_1's binary_logloss: 0.490963\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's auc: 0.883536\ttraining's binary_logloss: 0.424885\tvalid_1's auc: 0.819086\tvalid_1's binary_logloss: 0.493077\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8191  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 230.6   \u001b[0m | \u001b[0m 15.15   \u001b[0m | \u001b[0m 80.49   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.756798\ttraining's binary_logloss: 0.605924\tvalid_1's auc: 0.701253\tvalid_1's binary_logloss: 0.617905\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.756798\ttraining's binary_logloss: 0.606004\tvalid_1's auc: 0.701253\tvalid_1's binary_logloss: 0.618024\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7013  \u001b[0m | \u001b[0m 0.548   \u001b[0m | \u001b[0m 196.4   \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 119.5   \u001b[0m | \u001b[0m 48.27   \u001b[0m | \u001b[0m 27.53   \u001b[0m | \u001b[0m 0.522   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.935078\ttraining's binary_logloss: 0.428262\tvalid_1's auc: 0.822443\tvalid_1's binary_logloss: 0.517472\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.920215\ttraining's binary_logloss: 0.568229\tvalid_1's auc: 0.8289\tvalid_1's binary_logloss: 0.592464\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8289  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 205.5   \u001b[0m | \u001b[95m 6.0     \u001b[0m | \u001b[95m 16.38   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.969773\ttraining's binary_logloss: 0.387544\tvalid_1's auc: 0.815212\tvalid_1's binary_logloss: 0.518825\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.946619\ttraining's binary_logloss: 0.564117\tvalid_1's auc: 0.821152\tvalid_1's binary_logloss: 0.596607\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8212  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 133.2   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 171.6   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.878208\ttraining's binary_logloss: 0.491586\tvalid_1's auc: 0.799651\tvalid_1's binary_logloss: 0.534909\n",
      "[200]\ttraining's auc: 0.893763\ttraining's binary_logloss: 0.429266\tvalid_1's auc: 0.817794\tvalid_1's binary_logloss: 0.497558\n",
      "[300]\ttraining's auc: 0.905472\ttraining's binary_logloss: 0.396756\tvalid_1's auc: 0.819215\tvalid_1's binary_logloss: 0.489922\n",
      "[400]\ttraining's auc: 0.913214\ttraining's binary_logloss: 0.376217\tvalid_1's auc: 0.823218\tvalid_1's binary_logloss: 0.486182\n",
      "[500]\ttraining's auc: 0.921123\ttraining's binary_logloss: 0.359531\tvalid_1's auc: 0.822572\tvalid_1's binary_logloss: 0.485991\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's auc: 0.921123\ttraining's binary_logloss: 0.359531\tvalid_1's auc: 0.822572\tvalid_1's binary_logloss: 0.485991\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8226  \u001b[0m | \u001b[0m 0.6254  \u001b[0m | \u001b[0m 277.5   \u001b[0m | \u001b[0m 10.57   \u001b[0m | \u001b[0m 56.47   \u001b[0m | \u001b[0m 1.621   \u001b[0m | \u001b[0m 58.12   \u001b[0m | \u001b[0m 0.5259  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.932832\ttraining's binary_logloss: 0.430234\tvalid_1's auc: 0.825801\tvalid_1's binary_logloss: 0.514344\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.919044\ttraining's binary_logloss: 0.53175\tvalid_1's auc: 0.830708\tvalid_1's binary_logloss: 0.56833\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.8307  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 66.13   \u001b[0m | \u001b[95m 13.53   \u001b[0m | \u001b[95m 16.55   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 0.7872  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.811971\ttraining's binary_logloss: 0.553203\tvalid_1's auc: 0.754584\tvalid_1's binary_logloss: 0.582539\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.81049\ttraining's binary_logloss: 0.586559\tvalid_1's auc: 0.756392\tvalid_1's binary_logloss: 0.603531\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7564  \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 44.54   \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 137.1   \u001b[0m | \u001b[0m 42.12   \u001b[0m | \u001b[0m 29.76   \u001b[0m | \u001b[0m 0.9925  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894313\ttraining's binary_logloss: 0.464878\tvalid_1's auc: 0.79694\tvalid_1's binary_logloss: 0.526996\n",
      "[200]\ttraining's auc: 0.916272\ttraining's binary_logloss: 0.393032\tvalid_1's auc: 0.822701\tvalid_1's binary_logloss: 0.488466\n",
      "[300]\ttraining's auc: 0.926213\ttraining's binary_logloss: 0.361491\tvalid_1's auc: 0.826705\tvalid_1's binary_logloss: 0.484374\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's auc: 0.925305\ttraining's binary_logloss: 0.363942\tvalid_1's auc: 0.827092\tvalid_1's binary_logloss: 0.483774\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 0.8193  \u001b[0m | \u001b[0m 334.6   \u001b[0m | \u001b[0m 10.12   \u001b[0m | \u001b[0m 30.54   \u001b[0m | \u001b[0m 8.452   \u001b[0m | \u001b[0m 59.23   \u001b[0m | \u001b[0m 0.8597  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.858614\ttraining's binary_logloss: 0.50152\tvalid_1's auc: 0.792872\tvalid_1's binary_logloss: 0.5412\n",
      "[200]\ttraining's auc: 0.877073\ttraining's binary_logloss: 0.448907\tvalid_1's auc: 0.812887\tvalid_1's binary_logloss: 0.505644\n",
      "[300]\ttraining's auc: 0.886069\ttraining's binary_logloss: 0.423125\tvalid_1's auc: 0.815599\tvalid_1's binary_logloss: 0.494743\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's auc: 0.882186\ttraining's binary_logloss: 0.432624\tvalid_1's auc: 0.817536\tvalid_1's binary_logloss: 0.497524\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 97.18   \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 74.53   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.864743\ttraining's binary_logloss: 0.492631\tvalid_1's auc: 0.785447\tvalid_1's binary_logloss: 0.544838\n",
      "[200]\ttraining's auc: 0.885735\ttraining's binary_logloss: 0.431804\tvalid_1's auc: 0.802557\tvalid_1's binary_logloss: 0.507695\n",
      "[300]\ttraining's auc: 0.897001\ttraining's binary_logloss: 0.403347\tvalid_1's auc: 0.805656\tvalid_1's binary_logloss: 0.501009\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's auc: 0.892593\ttraining's binary_logloss: 0.413157\tvalid_1's auc: 0.807076\tvalid_1's binary_logloss: 0.50188\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 47.05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.877909\ttraining's binary_logloss: 0.492454\tvalid_1's auc: 0.79907\tvalid_1's binary_logloss: 0.536244\n",
      "[200]\ttraining's auc: 0.892784\ttraining's binary_logloss: 0.430873\tvalid_1's auc: 0.815212\tvalid_1's binary_logloss: 0.500302\n",
      "[300]\ttraining's auc: 0.903226\ttraining's binary_logloss: 0.399371\tvalid_1's auc: 0.820635\tvalid_1's binary_logloss: 0.488535\n",
      "[400]\ttraining's auc: 0.910299\ttraining's binary_logloss: 0.380033\tvalid_1's auc: 0.823347\tvalid_1's binary_logloss: 0.48462\n",
      "[500]\ttraining's auc: 0.918184\ttraining's binary_logloss: 0.364339\tvalid_1's auc: 0.821668\tvalid_1's binary_logloss: 0.485937\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\ttraining's auc: 0.918208\ttraining's binary_logloss: 0.364457\tvalid_1's auc: 0.821668\tvalid_1's binary_logloss: 0.486007\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8217  \u001b[0m | \u001b[0m 0.6457  \u001b[0m | \u001b[0m 278.1   \u001b[0m | \u001b[0m 9.807   \u001b[0m | \u001b[0m 57.98   \u001b[0m | \u001b[0m 2.659   \u001b[0m | \u001b[0m 56.61   \u001b[0m | \u001b[0m 0.9258  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815317\ttraining's binary_logloss: 0.555898\tvalid_1's auc: 0.755553\tvalid_1's binary_logloss: 0.580043\n",
      "[200]\ttraining's auc: 0.819845\ttraining's binary_logloss: 0.521473\tvalid_1's auc: 0.753228\tvalid_1's binary_logloss: 0.56494\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's auc: 0.819211\ttraining's binary_logloss: 0.548266\tvalid_1's auc: 0.759685\tvalid_1's binary_logloss: 0.575059\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.79491\ttraining's binary_logloss: 0.550343\tvalid_1's auc: 0.715393\tvalid_1's binary_logloss: 0.588517\n",
      "[200]\ttraining's auc: 0.813524\ttraining's binary_logloss: 0.521915\tvalid_1's auc: 0.746384\tvalid_1's binary_logloss: 0.56739\n",
      "[300]\ttraining's auc: 0.820036\ttraining's binary_logloss: 0.508588\tvalid_1's auc: 0.754907\tvalid_1's binary_logloss: 0.556754\n",
      "[400]\ttraining's auc: 0.819904\ttraining's binary_logloss: 0.500952\tvalid_1's auc: 0.759168\tvalid_1's binary_logloss: 0.550471\n",
      "[500]\ttraining's auc: 0.820191\ttraining's binary_logloss: 0.496435\tvalid_1's auc: 0.761364\tvalid_1's binary_logloss: 0.547268\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[377]\ttraining's auc: 0.821625\ttraining's binary_logloss: 0.502368\tvalid_1's auc: 0.759427\tvalid_1's binary_logloss: 0.551506\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 124.7   \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.877431\ttraining's binary_logloss: 0.481592\tvalid_1's auc: 0.789256\tvalid_1's binary_logloss: 0.534059\n",
      "[200]\ttraining's auc: 0.901051\ttraining's binary_logloss: 0.413718\tvalid_1's auc: 0.819215\tvalid_1's binary_logloss: 0.491542\n",
      "[300]\ttraining's auc: 0.915221\ttraining's binary_logloss: 0.378476\tvalid_1's auc: 0.818957\tvalid_1's binary_logloss: 0.486193\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's auc: 0.907204\ttraining's binary_logloss: 0.398451\tvalid_1's auc: 0.821927\tvalid_1's binary_logloss: 0.487974\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 72.65   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 50.65   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.969271\ttraining's binary_logloss: 0.38829\tvalid_1's auc: 0.814824\tvalid_1's binary_logloss: 0.520503\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's auc: 0.945806\ttraining's binary_logloss: 0.564396\tvalid_1's auc: 0.821281\tvalid_1's binary_logloss: 0.596639\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8213  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.851266\ttraining's binary_logloss: 0.508373\tvalid_1's auc: 0.786157\tvalid_1's binary_logloss: 0.545697\n",
      "[200]\ttraining's auc: 0.870119\ttraining's binary_logloss: 0.45889\tvalid_1's auc: 0.813404\tvalid_1's binary_logloss: 0.507865\n",
      "[300]\ttraining's auc: 0.878626\ttraining's binary_logloss: 0.433215\tvalid_1's auc: 0.816116\tvalid_1's binary_logloss: 0.495503\n",
      "[400]\ttraining's auc: 0.884612\ttraining's binary_logloss: 0.418505\tvalid_1's auc: 0.816761\tvalid_1's binary_logloss: 0.491845\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttraining's auc: 0.881123\ttraining's binary_logloss: 0.425474\tvalid_1's auc: 0.817536\tvalid_1's binary_logloss: 0.493211\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 84.3    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 499.5   \u001b[0m | \u001b[0m 15.07   \u001b[0m | \u001b[0m 48.43   \u001b[0m | \u001b[0m 49.47   \u001b[0m | \u001b[0m 36.26   \u001b[0m | \u001b[0m 0.63    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.844576\ttraining's binary_logloss: 0.517455\tvalid_1's auc: 0.773115\tvalid_1's binary_logloss: 0.559733\n",
      "[200]\ttraining's auc: 0.86086\ttraining's binary_logloss: 0.469532\tvalid_1's auc: 0.786996\tvalid_1's binary_logloss: 0.528786\n",
      "[300]\ttraining's auc: 0.868925\ttraining's binary_logloss: 0.445788\tvalid_1's auc: 0.792355\tvalid_1's binary_logloss: 0.515663\n",
      "[400]\ttraining's auc: 0.873082\ttraining's binary_logloss: 0.433711\tvalid_1's auc: 0.793195\tvalid_1's binary_logloss: 0.512039\n",
      "[500]\ttraining's auc: 0.876464\ttraining's binary_logloss: 0.425117\tvalid_1's auc: 0.797585\tvalid_1's binary_logloss: 0.509558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\ttraining's auc: 0.876583\ttraining's binary_logloss: 0.425254\tvalid_1's auc: 0.797585\tvalid_1's binary_logloss: 0.509559\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7976  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 34.2    \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 90.08   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815317\ttraining's binary_logloss: 0.555898\tvalid_1's auc: 0.755553\tvalid_1's binary_logloss: 0.580043\n",
      "[200]\ttraining's auc: 0.819845\ttraining's binary_logloss: 0.521473\tvalid_1's auc: 0.753228\tvalid_1's binary_logloss: 0.56494\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's auc: 0.819211\ttraining's binary_logloss: 0.548266\tvalid_1's auc: 0.759685\tvalid_1's binary_logloss: 0.575059\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 386.4   \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\ttraining's binary_logloss: 0.687876\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.683278\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 299.9   \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888996\ttraining's binary_logloss: 0.472544\tvalid_1's auc: 0.815987\tvalid_1's binary_logloss: 0.520059\n",
      "[200]\ttraining's auc: 0.91374\ttraining's binary_logloss: 0.401571\tvalid_1's auc: 0.831095\tvalid_1's binary_logloss: 0.483542\n",
      "[300]\ttraining's auc: 0.930084\ttraining's binary_logloss: 0.360343\tvalid_1's auc: 0.831224\tvalid_1's binary_logloss: 0.475646\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's auc: 0.922772\ttraining's binary_logloss: 0.379126\tvalid_1's auc: 0.832645\tvalid_1's binary_logloss: 0.477137\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m 0.8326  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 244.6   \u001b[0m | \u001b[95m 16.0    \u001b[0m | \u001b[95m 35.66   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 28.34   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성. \n",
    "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=2021)\n",
    "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행. \n",
    "lgbBO.maximize(init_points=5, n_iter=25) #초기 random iter 횟수 / drill down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.5,\n",
       "  'params': {'colsample_bytree': 0.8029891394037023,\n",
       "   'max_bin': 369.3509869848141,\n",
       "   'max_depth': 7.389471567283987,\n",
       "   'min_child_samples': 69.40788593239051,\n",
       "   'min_child_weight': 49.864920785675615,\n",
       "   'num_leaves': 29.126495016758426,\n",
       "   'subsample': 0.589496552975094}},\n",
       " {'target': 0.8203770661157025,\n",
       "  'params': {'colsample_bytree': 0.8764627143880469,\n",
       "   'max_bin': 334.4586520116717,\n",
       "   'max_depth': 13.843101321411226,\n",
       "   'min_child_samples': 28.409935225723554,\n",
       "   'min_child_weight': 3.869992969313764,\n",
       "   'num_leaves': 62.495839608415665,\n",
       "   'subsample': 0.8082787219472871}},\n",
       " {'target': 0.7647210743801653,\n",
       "  'params': {'colsample_bytree': 0.5433149806242736,\n",
       "   'max_bin': 285.02345762509634,\n",
       "   'max_depth': 12.165247086179901,\n",
       "   'min_child_samples': 193.1301743463701,\n",
       "   'min_child_weight': 29.140910428278865,\n",
       "   'num_leaves': 38.84643392631126,\n",
       "   'subsample': 0.7260726218947822}},\n",
       " {'target': 0.7925490702479339,\n",
       "  'params': {'colsample_bytree': 0.6009251239173098,\n",
       "   'max_bin': 288.95950784478055,\n",
       "   'max_depth': 7.950959743421153,\n",
       "   'min_child_samples': 120.90376310155581,\n",
       "   'min_child_weight': 24.339360206013698,\n",
       "   'num_leaves': 44.712576012046966,\n",
       "   'subsample': 0.9115493169826735}},\n",
       " {'target': 0.7627195247933883,\n",
       "  'params': {'colsample_bytree': 0.8661125134694954,\n",
       "   'max_bin': 43.837574664239604,\n",
       "   'max_depth': 12.721289350965124,\n",
       "   'min_child_samples': 132.26211320529916,\n",
       "   'min_child_weight': 41.57270414269909,\n",
       "   'num_leaves': 32.17877577419335,\n",
       "   'subsample': 0.8087444767155504}},\n",
       " {'target': 0.7896435950413223,\n",
       "  'params': {'colsample_bytree': 0.6744880277376619,\n",
       "   'max_bin': 291.1114059501559,\n",
       "   'max_depth': 8.588649284348628,\n",
       "   'min_child_samples': 115.65094603243443,\n",
       "   'min_child_weight': 23.945490223020627,\n",
       "   'num_leaves': 45.866817191629764,\n",
       "   'subsample': 0.996777015670472}},\n",
       " {'target': 0.8110795454545454,\n",
       "  'params': {'colsample_bytree': 0.7339802373026901,\n",
       "   'max_bin': 283.35993246765713,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 10.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.9664728471900691}},\n",
       " {'target': 0.819085743801653,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 230.56666754316956,\n",
       "   'max_depth': 15.151581200857606,\n",
       "   'min_child_samples': 80.48681993236356,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.7012525826446281,\n",
       "  'params': {'colsample_bytree': 0.547990844857161,\n",
       "   'max_bin': 196.42194968546357,\n",
       "   'max_depth': 14.758095403097709,\n",
       "   'min_child_samples': 119.49212139414757,\n",
       "   'min_child_weight': 48.27458534046469,\n",
       "   'num_leaves': 27.53243600861399,\n",
       "   'subsample': 0.5220307042481084}},\n",
       " {'target': 0.8288997933884298,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 205.50861316694997,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 16.3770581526668,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.8211518595041322,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 133.2355309850679,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 10.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.5,\n",
       "  'params': {'colsample_bytree': 1.0,\n",
       "   'max_bin': 171.56515540468246,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 10.0,\n",
       "   'min_child_weight': 50.0,\n",
       "   'num_leaves': 24.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.8225723140495868,\n",
       "  'params': {'colsample_bytree': 0.6254236932514583,\n",
       "   'max_bin': 277.51398992247306,\n",
       "   'max_depth': 10.567158773456832,\n",
       "   'min_child_samples': 56.47049709752268,\n",
       "   'min_child_weight': 1.6208784227411692,\n",
       "   'num_leaves': 58.12012831888779,\n",
       "   'subsample': 0.5258805867790606}},\n",
       " {'target': 0.8307076446280991,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 66.13023771112232,\n",
       "   'max_depth': 13.533190274241822,\n",
       "   'min_child_samples': 16.546655830201242,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.7871828669926123}},\n",
       " {'target': 0.7563920454545454,\n",
       "  'params': {'colsample_bytree': 0.7766719888058358,\n",
       "   'max_bin': 44.540048895805334,\n",
       "   'max_depth': 14.971490800313909,\n",
       "   'min_child_samples': 137.07853459456277,\n",
       "   'min_child_weight': 42.12216778006612,\n",
       "   'num_leaves': 29.761671066662228,\n",
       "   'subsample': 0.9925397212121176}},\n",
       " {'target': 0.8270919421487603,\n",
       "  'params': {'colsample_bytree': 0.8192510076130168,\n",
       "   'max_bin': 334.57826027225775,\n",
       "   'max_depth': 10.118717508740795,\n",
       "   'min_child_samples': 30.538614652848455,\n",
       "   'min_child_weight': 8.451683354283064,\n",
       "   'num_leaves': 59.23173993119104,\n",
       "   'subsample': 0.8596802031292511}},\n",
       " {'target': 0.8175361570247933,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 97.17992958039655,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 74.53305687089602,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.8070764462809917,\n",
       "  'params': {'colsample_bytree': 1.0,\n",
       "   'max_bin': 10.0,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 47.04606518355134,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 24.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.8216683884297521,\n",
       "  'params': {'colsample_bytree': 0.6456768385125404,\n",
       "   'max_bin': 278.0787703838887,\n",
       "   'max_depth': 9.80731282600458,\n",
       "   'min_child_samples': 57.98172098768582,\n",
       "   'min_child_weight': 2.6593352505934256,\n",
       "   'num_leaves': 56.60673988873834,\n",
       "   'subsample': 0.9258402710212532}},\n",
       " {'target': 0.5,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 10.0,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 10.0,\n",
       "   'min_child_weight': 50.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.7596849173553719,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 500.0,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.759426652892562,\n",
       "  'params': {'colsample_bytree': 1.0,\n",
       "   'max_bin': 124.69271500599773,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.821926652892562,\n",
       "  'params': {'colsample_bytree': 1.0,\n",
       "   'max_bin': 72.64849380176774,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 50.651956886603955,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 24.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.8212809917355373,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 500.0,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 10.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.8175361570247933,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 500.0,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 84.29712939364583,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.5,\n",
       "  'params': {'colsample_bytree': 0.7984374861049329,\n",
       "   'max_bin': 499.52806944124507,\n",
       "   'max_depth': 15.06827507587561,\n",
       "   'min_child_samples': 48.43436524882666,\n",
       "   'min_child_weight': 49.46723714462108,\n",
       "   'num_leaves': 36.2642472705072,\n",
       "   'subsample': 0.6299907646722975}},\n",
       " {'target': 0.7975852272727273,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 34.19673100200078,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 90.08486186705073,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.7596849173553719,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 386.41928697967717,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 1.0}},\n",
       " {'target': 0.5,\n",
       "  'params': {'colsample_bytree': 1.0,\n",
       "   'max_bin': 299.90536842197395,\n",
       "   'max_depth': 6.0,\n",
       "   'min_child_samples': 10.000000000000002,\n",
       "   'min_child_weight': 50.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.8326446280991736,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 244.59637674642823,\n",
       "   'max_depth': 16.0,\n",
       "   'min_child_samples': 35.657663580429876,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 28.33735096230287,\n",
       "   'subsample': 1.0}}]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BayesianOptimization객체의 res는 iteration 수행 시마다 모든 함수 반환결과와 그때의 파라미터 결과값을 가지고 있음. \n",
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.8203770661157025, 0.7647210743801653, 0.7925490702479339, 0.7627195247933883, 0.7896435950413223, 0.8110795454545454, 0.819085743801653, 0.7012525826446281, 0.8288997933884298, 0.8211518595041322, 0.5, 0.8225723140495868, 0.8307076446280991, 0.7563920454545454, 0.8270919421487603, 0.8175361570247933, 0.8070764462809917, 0.8216683884297521, 0.5, 0.7596849173553719, 0.759426652892562, 0.821926652892562, 0.8212809917355373, 0.8175361570247933, 0.5, 0.7975852272727273, 0.7596849173553719, 0.5, 0.8326446280991736]\n",
      "maximum target index: 29\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmax(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.8326446280991736, 'params': {'colsample_bytree': 0.5, 'max_bin': 244.59637674642823, 'max_depth': 16.0, 'min_child_samples': 35.657663580429876, 'min_child_weight': 1.0, 'num_leaves': 28.33735096230287, 'subsample': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888754\ttraining's binary_logloss: 0.479575\tvalid_1's auc: 0.873214\tvalid_1's binary_logloss: 0.483405\n",
      "[200]\ttraining's auc: 0.912209\ttraining's binary_logloss: 0.409394\tvalid_1's auc: 0.88244\tvalid_1's binary_logloss: 0.432561\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's auc: 0.910738\ttraining's binary_logloss: 0.413816\tvalid_1's auc: 0.883929\tvalid_1's binary_logloss: 0.434394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5, learning_rate=0.01, max_bin=244,\n",
       "               max_depth=16, min_child_samples=35, min_child_weight=1.0,\n",
       "               n_estimators=500, num_leaves=28)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.01,\n",
    "        'max_depth': 16, #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': 28, \n",
    "        'min_child_samples': 35,\n",
    "        'min_child_weight': 1.0,\n",
    "        'subsample': 1.0, \n",
    "        'colsample_bytree': 0.5,\n",
    "        'max_bin': 244\n",
    "    }\n",
    "model = LGBMClassifier(**params)\n",
    "model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_valid, y_valid)], eval_metric= 'auc', verbose= 100, \n",
    "                early_stopping_rounds= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OOF 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_train, x_valid):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    \n",
    "    x_train[features] = scaler.fit_transform(x_train[features])\n",
    "    x_valid[features] = scaler.fit_transform(x_valid[features])\n",
    "    \n",
    "   \n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.96017\ttraining's binary_logloss: 0.392983\tvalid_1's auc: 0.826744\tvalid_1's binary_logloss: 0.49936\n",
      "[200]\ttraining's auc: 0.977632\ttraining's binary_logloss: 0.296646\tvalid_1's auc: 0.833721\tvalid_1's binary_logloss: 0.480835\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's auc: 0.975548\ttraining's binary_logloss: 0.310678\tvalid_1's auc: 0.834884\tvalid_1's binary_logloss: 0.481142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.965662\ttraining's binary_logloss: 0.382727\tvalid_1's auc: 0.812355\tvalid_1's binary_logloss: 0.519209\n",
      "[200]\ttraining's auc: 0.980044\ttraining's binary_logloss: 0.291558\tvalid_1's auc: 0.824419\tvalid_1's binary_logloss: 0.498203\n",
      "[300]\ttraining's auc: 0.987409\ttraining's binary_logloss: 0.248399\tvalid_1's auc: 0.82093\tvalid_1's binary_logloss: 0.507987\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's auc: 0.980537\ttraining's binary_logloss: 0.28871\tvalid_1's auc: 0.824709\tvalid_1's binary_logloss: 0.497486\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.960901\ttraining's binary_logloss: 0.384109\tvalid_1's auc: 0.810465\tvalid_1's binary_logloss: 0.510011\n",
      "[200]\ttraining's auc: 0.975749\ttraining's binary_logloss: 0.29243\tvalid_1's auc: 0.818314\tvalid_1's binary_logloss: 0.49427\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's auc: 0.971711\ttraining's binary_logloss: 0.314927\tvalid_1's auc: 0.821076\tvalid_1's binary_logloss: 0.493063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.960133\ttraining's binary_logloss: 0.383499\tvalid_1's auc: 0.792297\tvalid_1's binary_logloss: 0.53128\n",
      "[200]\ttraining's auc: 0.977887\ttraining's binary_logloss: 0.285163\tvalid_1's auc: 0.797384\tvalid_1's binary_logloss: 0.524033\n",
      "[300]\ttraining's auc: 0.98792\ttraining's binary_logloss: 0.232663\tvalid_1's auc: 0.800872\tvalid_1's binary_logloss: 0.529992\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's auc: 0.978235\ttraining's binary_logloss: 0.28371\tvalid_1's auc: 0.798547\tvalid_1's binary_logloss: 0.523649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.962882\ttraining's binary_logloss: 0.390513\tvalid_1's auc: 0.854018\tvalid_1's binary_logloss: 0.481725\n",
      "[200]\ttraining's auc: 0.976781\ttraining's binary_logloss: 0.296679\tvalid_1's auc: 0.870238\tvalid_1's binary_logloss: 0.429688\n",
      "[300]\ttraining's auc: 0.983703\ttraining's binary_logloss: 0.258121\tvalid_1's auc: 0.876488\tvalid_1's binary_logloss: 0.415273\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttraining's auc: 0.980632\ttraining's binary_logloss: 0.270709\tvalid_1's auc: 0.878869\tvalid_1's binary_logloss: 0.41541\n",
      "accuracy Score : 0.7606\n",
      "f1 Score : 0.6351\n",
      "auc Score : 0.7229\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = list()\n",
    "f1_scores = list()\n",
    "auc_scores = list()\n",
    "\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(x_data, y_data)):\n",
    "    x_train, y_train = x_data.iloc[trn_idx, :], y_data[trn_idx]\n",
    "    x_valid, y_valid = x_data.iloc[val_idx, :], y_data[val_idx]\n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid= preprocess(x_train, x_valid)\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":500, \"learning_rate\":0.01,\n",
    "        'max_depth': 6, #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 \n",
    "        'num_leaves': 64, \n",
    "        'min_child_samples': 10,\n",
    "        'min_child_weight': 1.0,\n",
    "        'subsample': 0.63, \n",
    "        'colsample_bytree': 1.0,\n",
    "        'max_bin': 150\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    model.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_valid, y_valid)], eval_metric= 'auc', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "\n",
    "    # 훈련, 검증 데이터 Log Loss 확인\n",
    "    val_accuracy = accuracy_score(y_valid, model.predict(x_valid))\n",
    "    f1_accuracy = f1_score(y_valid, model.predict(x_valid))\n",
    "    auc_accuracy = roc_auc_score(y_valid, model.predict(x_valid))\n",
    "    accuracy_scores.append(val_accuracy)\n",
    "    f1_scores.append(f1_accuracy)\n",
    "    auc_scores.append(auc_accuracy)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "# 교차 검증 Log Loss 평균 계산하기\n",
    "print('accuracy Score : {:.4f}'.format(np.mean(accuracy_scores)))\n",
    "print('f1 Score : {:.4f}'.format(np.mean(f1_scores)))\n",
    "print('auc Score : {:.4f}'.format(np.mean(auc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
